{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "FILE_PATH = r'C:\\Users\\yashs\\Desktop\\Project\\Fintech Credit Risk\\accepted_2007_to_2018Q4.csv'\n",
    "TARGET_YEARS = [2016, 2017, 2018]\n",
    "CHUNK_SIZE = 100000\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# XGBoost Hyperparameters (tuned for recall/profit)\n",
    "XGB_PARAMS = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'scale_pos_weight': 4,  # Critical: Penalty for missing defaults (4:1 cost ratio)\n",
    "    'n_jobs': -1,\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "def load_modern_data(file_path, years):\n",
    "    \"\"\"\n",
    "    Reads the large CSV in chunks to filter for specific years without blowing up RAM.\n",
    "    \"\"\"\n",
    "    print(f\"--> Starting Data Extraction for years: {years}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    # Iterate through file\n",
    "    for chunk in pd.read_csv(file_path, chunksize=CHUNK_SIZE, low_memory=False):\n",
    "        \n",
    "        # 1. Basic filter: Closed loans only\n",
    "        chunk = chunk[chunk['loan_status'].isin(['Fully Paid', 'Charged Off'])]\n",
    "        \n",
    "        # 2. Year extraction (Handling 'Mon-YYYY' format)\n",
    "        chunk['year'] = chunk['issue_d'].astype(str).str[-4:].astype(int)\n",
    "        \n",
    "        # 3. Filter for target era\n",
    "        valid_rows = chunk[chunk['year'].isin(years)]\n",
    "        \n",
    "        if not valid_rows.empty:\n",
    "            chunks.append(valid_rows)\n",
    "            # Optional: Print progress every few chunks if needed\n",
    "            # print(f\"   Buffered {len(valid_rows)} rows...\")\n",
    "\n",
    "    df = pd.concat(chunks, axis=0)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"--> Extraction Complete. Loaded {len(df):,} rows in {elapsed:.1f}s.\")\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Cleans raw data and generates financial metrics.\n",
    "    \"\"\"\n",
    "    print(\"--> Processing Features & Engineering Targets...\")\n",
    "    \n",
    "    # 1. Financial Metric: Actual Profit (Cash In - Cash Out)\n",
    "    df['Actual_Profit'] = df['total_pymnt'] - df['funded_amnt']\n",
    "    \n",
    "    # 2. Target Definition: 1 = Default (Charged Off), 0 = Paid\n",
    "    df['target'] = df['loan_status'].apply(lambda x: 1 if x == 'Charged Off' else 0)\n",
    "    \n",
    "    # 3. Feature Selection\n",
    "    features = [\n",
    "        'loan_amnt', 'term', 'int_rate', 'sub_grade', 'emp_length',\n",
    "        'home_ownership', 'annual_inc', 'verification_status',\n",
    "        'purpose', 'dti', 'fico_range_high', 'revol_util'\n",
    "    ]\n",
    "    \n",
    "    X = df[features].copy()\n",
    "    y = df['target']\n",
    "    \n",
    "    # 4. Cleaning\n",
    "    # Term: \" 36 months\" -> 36\n",
    "    X['term'] = X['term'].astype(str).str.replace(' months', '').astype(int)\n",
    "    \n",
    "    # Emp Length: Map text to int, fill NaN with 0\n",
    "    emp_map = {\n",
    "        '< 1 year': 0, '1 year': 1, '2 years': 2, '3 years': 3, '4 years': 4,\n",
    "        '5 years': 5, '6 years': 6, '7 years': 7, '8 years': 8, '9 years': 9, '10+ years': 10\n",
    "    }\n",
    "    X['emp_length'] = X['emp_length'].map(emp_map).fillna(0).astype(int)\n",
    "    \n",
    "    # Numeric Imputation (Median is safer for income/dti)\n",
    "    for col in ['dti', 'revol_util', 'annual_inc']:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "        \n",
    "    # 5. Encoding\n",
    "    # Ordinal Encode Sub-Grade (A1->0, A2->1, ... G5->34)\n",
    "    # This preserves the \"Risk Ranking\" inherent in grades\n",
    "    grade_map = {grade: i for i, grade in enumerate(sorted(X['sub_grade'].unique()))}\n",
    "    X['sub_grade'] = X['sub_grade'].map(grade_map)\n",
    "    \n",
    "    # One-Hot Encode others\n",
    "    X = pd.get_dummies(X, columns=['home_ownership', 'verification_status', 'purpose'], drop_first=True)\n",
    "    \n",
    "    print(f\"--> Data Ready. Feature Matrix Shape: {X.shape}\")\n",
    "    print(f\"--> Default Rate: {y.mean():.2%}\")\n",
    "    \n",
    "    return X, y, df[['Actual_Profit', 'sub_grade', 'int_rate', 'term']]\n",
    "\n",
    "def generate_visuals(results, model, feature_names):\n",
    "    \"\"\"\n",
    "    Generates the 3 key portfolio charts.\n",
    "    \"\"\"\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    \n",
    "    # Chart 1: The Money Slide (Profit Distribution)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    results['Outcome'] = results.apply(lambda x: 'REJECTED (Risk Avoided)' if x['Pred'] == 1 else 'APPROVED (Profit Generated)', axis=1)\n",
    "    \n",
    "    sns.histplot(data=results, x='Actual_Profit', hue='Outcome', element=\"step\", bins=50, \n",
    "                 palette={'REJECTED (Risk Avoided)': '#FF4B4B', 'APPROVED (Profit Generated)': '#2ECC71'}, alpha=0.6)\n",
    "    \n",
    "    plt.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.title('Financial Impact: Identifying Toxic Assets', fontsize=16, fontweight='bold', pad=15)\n",
    "    plt.xlabel('Net Profit/Loss per Loan (€)')\n",
    "    plt.legend(title='Model Decision', labels=['APPROVED (Profit Generated)', 'REJECTED (Risk Avoided)'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Chart 2: Feature Importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    importances = pd.Series(model.feature_importances_, index=feature_names).sort_values(ascending=False).head(10)\n",
    "    sns.barplot(x=importances.values, y=importances.index, palette='viridis')\n",
    "    plt.title('Top 10 Drivers of Credit Risk', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Chart 3: Risk by Grade (Validation)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    grade_risk = results.groupby('sub_grade')['target'].mean().reset_index().sort_values('sub_grade')\n",
    "    \n",
    "    sns.barplot(x='sub_grade', y='target', data=grade_risk, palette='magma', order=grade_risk['sub_grade'])\n",
    "    plt.axhline(results['target'].mean(), color='red', linestyle='--', label='Portfolio Avg')\n",
    "    plt.title('Default Rate by Loan Sub-Grade', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Actual Default Rate')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. Load Data\n",
    "    raw_df = load_modern_data(FILE_PATH, TARGET_YEARS)\n",
    "    \n",
    "    # 2. Preprocessing\n",
    "    X, y, financial_df = feature_engineering(raw_df)\n",
    "    \n",
    "    # 3. Split (Stratified to keep default rate consistent)\n",
    "    # We pass financial_df to keep the profit data aligned with the split\n",
    "    X_train, X_test, y_train, y_test, df_train, df_test = train_test_split(\n",
    "        X, y, financial_df, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # 4. Train Model\n",
    "    print(f\"--> Training XGBoost on {len(X_train):,} loans...\")\n",
    "    model = xgb.XGBClassifier(**XGB_PARAMS)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"--> Training Complete.\")\n",
    "    \n",
    "    # 5. Financial Evaluation\n",
    "    print(\"--> Calculating ROI on Test Set...\")\n",
    "    df_test['Pred'] = model.predict(X_test)\n",
    "    df_test['target'] = y_test  # Add target back for visualization\n",
    "    \n",
    "    baseline_profit = df_test['Actual_Profit'].sum()\n",
    "    model_profit = df_test[df_test['Pred'] == 0]['Actual_Profit'].sum()\n",
    "    value_created = model_profit - baseline_profit\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\" RESULTS SUMMARY (Test Set: {len(X_test):,} loans)\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Baseline Profit (No Model):   €{baseline_profit:,.0f}\")\n",
    "    print(f\"Model Profit (Optimization):  €{model_profit:,.0f}\")\n",
    "    print(f\"NET VALUE CREATED:            €{value_created:,.0f}\")\n",
    "    print(\"=\"*40 + \"\\n\")\n",
    "    \n",
    "    # 6. Generate Charts\n",
    "    generate_visuals(df_test, model, X.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
